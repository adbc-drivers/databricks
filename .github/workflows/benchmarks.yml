# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.

name: Performance Benchmarks

on:
  push:
    branches:
      - main
    paths:
      - '.github/workflows/benchmarks.yml'
      - 'csharp/src/**'
      - 'csharp/Benchmarks/**'
  pull_request:
    types: [labeled]  # Trigger when a label is added to the PR
  workflow_dispatch:
    inputs:
      query:
        description: 'Custom SQL query to benchmark (optional)'
        required: false
        type: string

concurrency:
  group: ${{ github.repository }}-${{ github.sha }}-${{ github.workflow }}
  cancel-in-progress: true

permissions:
  contents: write       # Required to push benchmark results to gh-pages branch
  pull-requests: write  # Required to post comparison comments on PRs

jobs:
  benchmark-net8:
    name: Benchmark (.NET 8.0)
    if: |
      github.event_name == 'push' ||
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'benchmark'))
    runs-on: ubuntu-latest
    timeout-minutes: 30
    environment: azure-prod
    env:
      DATABRICKS_SERVER_HOSTNAME: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_HTTP_PATH: ${{ secrets.TEST_PECO_WAREHOUSE_HTTP_PATH }}
      DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_TEST_CLIENT_ID }}
      DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_TEST_CLIENT_SECRET }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: Create Databricks config file
        run: |
          mkdir -p ~/.databricks
          BENCHMARK_QUERY="${{ github.event.inputs.query }}"
          if [ -z "$BENCHMARK_QUERY" ]; then
            BENCHMARK_QUERY="select * from main.tpcds_sf1_delta.catalog_sales"
          fi
          cat > ~/.databricks/connection.json << EOF
          {
            "uri": "https://${{ env.DATABRICKS_SERVER_HOSTNAME }}${{ env.DATABRICKS_HTTP_PATH }}",
            "auth_type": "oauth",
            "grant_type": "client_credentials",
            "client_id": "${{ env.DATABRICKS_CLIENT_ID }}",
            "client_secret": "${{ env.DATABRICKS_CLIENT_SECRET }}",
            "type": "databricks",
            "catalog": "main",
            "db_schema": "ADBC_Testing",
            "query": "$BENCHMARK_QUERY"
          }
          EOF
          echo "DATABRICKS_TEST_CONFIG_FILE=$HOME/.databricks/connection.json" >> $GITHUB_ENV

      - name: Build
        shell: bash
        run: |
          ./ci/scripts/csharp_build.sh "${{ github.workspace }}"

      - name: Run Benchmark (net8.0)
        shell: bash
        run: |
          export DATABRICKS_TEST_CONFIG_FILE="$HOME/.databricks/connection.json"
          ./ci/scripts/csharp_benchmark.sh "${{ github.workspace }}" "net8.0"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-net8
          path: |
            csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/*
          retention-days: 90

      - name: Extract benchmark data for trend tracking
        id: extract-data
        run: |
          # Parse BenchmarkDotNet JSON results for trend tracking
          RESULTS_FILE=$(find csharp/Benchmarks/BenchmarkDotNet.Artifacts/results -name "*-report-full-compressed.json" | head -n 1)
          METRICS_FILE=$(find /tmp -name "cloudfetch_benchmark_metrics.json" 2>/dev/null | head -n 1)

          if [ -f "$RESULTS_FILE" ]; then
            echo "Found BenchmarkDotNet results file: $RESULTS_FILE"

            # Extract memory metrics from BenchmarkDotNet JSON
            ALLOCATED_BYTES=$(jq -r '.Benchmarks[0].Memory.BytesAllocatedPerOperation // 0' "$RESULTS_FILE")
            ALLOCATED_MB=$(echo "scale=2; $ALLOCATED_BYTES / 1024 / 1024" | bc)
            echo "allocated_mb=$ALLOCATED_MB" >> $GITHUB_OUTPUT
            echo "Allocated memory: ${ALLOCATED_MB} MB"

            GEN2_COLLECTIONS=$(jq -r '.Benchmarks[0].Memory.Gen2Collections // 0' "$RESULTS_FILE")
            echo "gen2_collections=$GEN2_COLLECTIONS" >> $GITHUB_OUTPUT
            echo "Gen2 collections: $GEN2_COLLECTIONS"

            # Extract timing metrics (convert from nanoseconds to seconds)
            MIN_TIME_NS=$(jq -r '.Benchmarks[0].Statistics.Min // 0' "$RESULTS_FILE")
            MIN_TIME_S=$(echo "scale=3; $MIN_TIME_NS / 1000000000" | bc)
            echo "min_time_s=$MIN_TIME_S" >> $GITHUB_OUTPUT
            echo "Min execution time: ${MIN_TIME_S} seconds"
          else
            echo "Warning: Could not find BenchmarkDotNet results file"
          fi

          # Extract peak memory from custom metrics file
          if [ -f "$METRICS_FILE" ]; then
            echo "Found custom metrics file: $METRICS_FILE"
            PEAK_MEMORY_MB=$(jq -r 'to_entries | .[0].value.PeakMemoryMB' "$METRICS_FILE")
            echo "peak_memory_mb=$PEAK_MEMORY_MB" >> $GITHUB_OUTPUT
            echo "Peak memory: ${PEAK_MEMORY_MB} MB"
          else
            echo "Warning: Could not find custom metrics file"
          fi

      - name: Create benchmark data file for trend tracking
        if: steps.extract-data.outputs.peak_memory_mb != ''
        run: |
          mkdir -p csharp/Benchmarks/BenchmarkDotNet.Artifacts/results
          cat > csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json << EOF
          [
            {
              "name": "Min Execution Time (s)",
              "unit": "seconds",
              "value": ${{ steps.extract-data.outputs.min_time_s }}
            },
            {
              "name": "Peak Memory (MB)",
              "unit": "MB",
              "value": ${{ steps.extract-data.outputs.peak_memory_mb }}
            },
            {
              "name": "Allocated Memory (MB)",
              "unit": "MB",
              "value": ${{ steps.extract-data.outputs.allocated_mb }}
            },
            {
              "name": "Gen2 Collections",
              "unit": "collections",
              "value": ${{ steps.extract-data.outputs.gen2_collections }}
            }
          ]
          EOF

      - name: Store benchmark results for trend tracking
        uses: benchmark-action/github-action-benchmark@v1
        if: steps.extract-data.outputs.peak_memory_mb != '' && github.event_name == 'push' && github.ref == 'refs/heads/main'
        with:
          tool: 'customSmallerIsBetter'
          output-file-path: csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: false
          fail-on-alert: false
          alert-comment-cc-users: '@databricks/adbc-csharp-maintainers'
          benchmark-data-dir-path: 'bench/net8'

      - name: Download baseline benchmark data from gh-pages
        if: steps.extract-data.outputs.peak_memory_mb != '' && steps.extract-data.outputs.min_time_s != '' && github.event_name == 'pull_request'
        run: |
          # Create cache directory
          mkdir -p ./cache

          # Fetch gh-pages branch
          git fetch origin gh-pages --depth=1

          # Extract baseline data from gh-pages
          git show origin/gh-pages:bench/net8/data.js > ./cache/data.js || echo "[]" > ./cache/data.js

          # Convert from data.js format to JSON
          # data.js has format: window.BENCHMARK_DATA = { entries: { "Benchmark": [...] } }
          # We need to extract the last entry's benches array
          node -e "
            const fs = require('fs');
            const content = fs.readFileSync('./cache/data.js', 'utf8');
            const dataMatch = content.match(/window\.BENCHMARK_DATA\s*=\s*(.+)/s);
            if (dataMatch) {
              const data = JSON.parse(dataMatch[1]);
              // entries is an object with 'Benchmark' key, not an array
              const benchmarkEntries = data.entries['Benchmark'] || data.entries[Object.keys(data.entries)[0]] || [];
              const lastEntry = benchmarkEntries[benchmarkEntries.length - 1];
              if (lastEntry && lastEntry.benches) {
                fs.writeFileSync('./cache/benchmark-data.json', JSON.stringify(lastEntry.benches, null, 2));
              } else {
                fs.writeFileSync('./cache/benchmark-data.json', '[]');
              }
            } else {
              fs.writeFileSync('./cache/benchmark-data.json', '[]');
            }
          " || echo "[]" > ./cache/benchmark-data.json

      - name: Post PR comment with benchmark comparison (.NET 8.0)
        if: github.event_name == 'pull_request' && steps.extract-data.outputs.peak_memory_mb != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const currentData = JSON.parse(fs.readFileSync('csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json', 'utf8'));

            let baselineData = [];
            try {
              baselineData = JSON.parse(fs.readFileSync('./cache/benchmark-data.json', 'utf8'));
            } catch (e) {
              console.log('No baseline data found');
            }

            const currentMetrics = {};
            currentData.forEach(item => { currentMetrics[item.name] = item.value; });
            const baselineMetrics = {};
            baselineData.forEach(item => { baselineMetrics[item.name] = item.value; });

            let tableRows = '';
            ['Min Execution Time (s)', 'Peak Memory (MB)', 'Allocated Memory (MB)', 'Gen2 Collections'].forEach(metricName => {
              const current = currentMetrics[metricName] || 0;
              const baseline = baselineMetrics[metricName] || 0;
              let change = 'N/A';
              let status = 'âž–';

              if (baseline > 0) {
                const changePercent = ((current - baseline) / baseline) * 100;
                change = (changePercent >= 0 ? '+' : '') + changePercent.toFixed(1) + '%';
                status = changePercent < -30 ? 'ðŸŸ¢' : changePercent > 30 ? 'âš ï¸' : 'âœ…';
              } else {
                change = 'New metric';
              }
              tableRows += `| ${metricName} | ${baseline.toFixed(3)} | ${current.toFixed(3)} | ${change} | ${status} |\n`;
            });

            const body = `## ðŸŽ¯ Benchmark Results (.NET 8.0)

            | Metric | Baseline (main) | This PR | Change | Status |
            |--------|----------------|---------|--------|--------|
            ${tableRows}
            **Indicators:**
            - ðŸŸ¢ **Improvement** - Metric improved by >30%
            - âœ… **No significant change** - Within Â±30%
            - âš ï¸ **Regression** - Metric degraded by >30%
            - âž– **New metric** - No baseline data available

            ðŸ“Š [View detailed results](${context.payload.repository.html_url}/actions/runs/${context.runId})`;

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.data.find(comment =>
              comment.user.login === 'github-actions[bot]' &&
              comment.body.includes('Benchmark Results (.NET 8.0)')
            );

            if (existingComment) {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
              });
            }

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

  benchmark-net472:
    name: Benchmark (.NET Framework 4.7.2)
    if: |
      github.event_name == 'push' ||
      github.event_name == 'workflow_dispatch' ||
      (github.event_name == 'pull_request' && contains(github.event.pull_request.labels.*.name, 'benchmark'))
    runs-on: windows-2022
    timeout-minutes: 30
    environment: azure-prod
    env:
      DATABRICKS_SERVER_HOSTNAME: ${{ secrets.DATABRICKS_HOST }}
      DATABRICKS_HTTP_PATH: ${{ secrets.TEST_PECO_WAREHOUSE_HTTP_PATH }}
      DATABRICKS_CLIENT_ID: ${{ secrets.DATABRICKS_TEST_CLIENT_ID }}
      DATABRICKS_CLIENT_SECRET: ${{ secrets.DATABRICKS_TEST_CLIENT_SECRET }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Set up .NET
        uses: actions/setup-dotnet@v4
        with:
          dotnet-version: '8.0.x'

      - name: Create Databricks config file
        shell: pwsh
        run: |
          $configDir = Join-Path $env:USERPROFILE ".databricks"
          New-Item -ItemType Directory -Force -Path $configDir | Out-Null

          $benchmarkQuery = "${{ github.event.inputs.query }}"
          if ([string]::IsNullOrEmpty($benchmarkQuery)) {
            $benchmarkQuery = "select * from main.tpcds_sf1_delta.catalog_sales"
          }

          $config = @{
            uri = "https://${{ env.DATABRICKS_SERVER_HOSTNAME }}${{ env.DATABRICKS_HTTP_PATH }}"
            auth_type = "oauth"
            grant_type = "client_credentials"
            client_id = "${{ env.DATABRICKS_CLIENT_ID }}"
            client_secret = "${{ env.DATABRICKS_CLIENT_SECRET }}"
            type = "databricks"
            catalog = "main"
            db_schema = "ADBC_Testing"
            query = $benchmarkQuery
          } | ConvertTo-Json

          $configPath = Join-Path $configDir "connection.json"
          $config | Out-File -FilePath $configPath -Encoding utf8
          echo "DATABRICKS_TEST_CONFIG_FILE=$configPath" >> $env:GITHUB_ENV

      - name: Build
        shell: bash
        run: |
          ./ci/scripts/csharp_build.sh "${{ github.workspace }}"

      - name: Run Benchmark (net472)
        shell: bash
        run: |
          export DATABRICKS_TEST_CONFIG_FILE="$HOME/.databricks/connection.json"
          ./ci/scripts/csharp_benchmark.sh "${{ github.workspace }}" "net472"

      - name: Upload benchmark results
        uses: actions/upload-artifact@v4
        with:
          name: benchmark-results-net472
          path: |
            csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/*
          retention-days: 90

      - name: Extract benchmark data for trend tracking
        id: extract-data
        shell: pwsh
        run: |
          $resultsFile = Get-ChildItem -Path "csharp/Benchmarks/BenchmarkDotNet.Artifacts/results" -Filter "*-report-full-compressed.json" | Select-Object -First 1
          $metricsFile = Get-ChildItem -Path $env:TEMP -Filter "cloudfetch_benchmark_metrics.json" -ErrorAction SilentlyContinue | Select-Object -First 1

          if ($resultsFile) {
            Write-Host "Found BenchmarkDotNet results file: $($resultsFile.FullName)"
            $results = Get-Content $resultsFile.FullName | ConvertFrom-Json

            # Extract memory metrics from BenchmarkDotNet JSON
            $allocatedBytes = if ($results.Benchmarks[0].Memory.BytesAllocatedPerOperation) { $results.Benchmarks[0].Memory.BytesAllocatedPerOperation } else { 0 }
            $allocatedMB = [math]::Round($allocatedBytes / 1024 / 1024, 2)
            echo "allocated_mb=$allocatedMB" >> $env:GITHUB_OUTPUT
            Write-Host "Allocated memory: ${allocatedMB} MB"

            $gen2Collections = if ($results.Benchmarks[0].Memory.Gen2Collections) { $results.Benchmarks[0].Memory.Gen2Collections } else { 0 }
            echo "gen2_collections=$gen2Collections" >> $env:GITHUB_OUTPUT
            Write-Host "Gen2 collections: $gen2Collections"

            # Extract timing metrics (convert from nanoseconds to seconds)
            $minTimeNs = if ($results.Benchmarks[0].Statistics.Min) { $results.Benchmarks[0].Statistics.Min } else { 0 }
            $minTimeS = [math]::Round($minTimeNs / 1000000000, 3)
            echo "min_time_s=$minTimeS" >> $env:GITHUB_OUTPUT
            Write-Host "Min execution time: ${minTimeS} seconds"
          } else {
            Write-Host "Warning: Could not find BenchmarkDotNet results file"
          }

          # Extract peak memory from custom metrics file
          if ($metricsFile) {
            Write-Host "Found custom metrics file: $($metricsFile.FullName)"
            $metrics = Get-Content $metricsFile.FullName | ConvertFrom-Json
            $peakMemoryMB = ($metrics.PSObject.Properties | Select-Object -First 1).Value.PeakMemoryMB
            echo "peak_memory_mb=$peakMemoryMB" >> $env:GITHUB_OUTPUT
            Write-Host "Peak memory: ${peakMemoryMB} MB"
          } else {
            Write-Host "Warning: Could not find custom metrics file"
          }

      - name: Create benchmark data file for trend tracking
        if: steps.extract-data.outputs.peak_memory_mb != ''
        shell: pwsh
        run: |
          New-Item -ItemType Directory -Force -Path "csharp/Benchmarks/BenchmarkDotNet.Artifacts/results" | Out-Null
          $benchmarkData = @(
            @{
              name = "Min Execution Time (s)"
              unit = "seconds"
              value = [double]"${{ steps.extract-data.outputs.min_time_s }}"
            },
            @{
              name = "Peak Memory (MB)"
              unit = "MB"
              value = [double]"${{ steps.extract-data.outputs.peak_memory_mb }}"
            },
            @{
              name = "Allocated Memory (MB)"
              unit = "MB"
              value = [double]"${{ steps.extract-data.outputs.allocated_mb }}"
            },
            @{
              name = "Gen2 Collections"
              unit = "collections"
              value = [double]"${{ steps.extract-data.outputs.gen2_collections }}"
            }
          ) | ConvertTo-Json
          $benchmarkData | Out-File -FilePath "csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json" -Encoding utf8

      - name: Store benchmark results for trend tracking
        uses: benchmark-action/github-action-benchmark@v1
        if: steps.extract-data.outputs.peak_memory_mb != '' && github.event_name == 'push' && github.ref == 'refs/heads/main'
        with:
          tool: 'customSmallerIsBetter'
          output-file-path: csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '150%'
          comment-on-alert: false
          fail-on-alert: false
          alert-comment-cc-users: '@databricks/adbc-csharp-maintainers'
          benchmark-data-dir-path: 'bench/net472'

      - name: Download baseline benchmark data from gh-pages
        if: steps.extract-data.outputs.peak_memory_mb != '' && steps.extract-data.outputs.min_time_s != '' && github.event_name == 'pull_request'
        shell: bash
        run: |
          # Create cache directory
          mkdir -p ./cache

          # Fetch gh-pages branch
          git fetch origin gh-pages --depth=1

          # Extract baseline data from gh-pages
          git show origin/gh-pages:bench/net472/data.js > ./cache/data.js || echo "[]" > ./cache/data.js

          # Convert from data.js format to JSON (using Node.js which works reliably)
          # data.js has format: window.BENCHMARK_DATA = { entries: { "Benchmark": [...] } }
          node -e "
            const fs = require('fs');
            const content = fs.readFileSync('./cache/data.js', 'utf8');
            const dataMatch = content.match(/window\.BENCHMARK_DATA\s*=\s*(.+)/s);
            if (dataMatch) {
              const data = JSON.parse(dataMatch[1]);
              // entries is an object with 'Benchmark' key, not an array
              const benchmarkEntries = data.entries['Benchmark'] || data.entries[Object.keys(data.entries)[0]] || [];
              const lastEntry = benchmarkEntries[benchmarkEntries.length - 1];
              if (lastEntry && lastEntry.benches) {
                fs.writeFileSync('./cache/benchmark-data.json', JSON.stringify(lastEntry.benches, null, 2));
              } else {
                fs.writeFileSync('./cache/benchmark-data.json', '[]');
              }
            } else {
              fs.writeFileSync('./cache/benchmark-data.json', '[]');
            }
          " || echo "[]" > ./cache/benchmark-data.json

      - name: Post PR comment with benchmark comparison (.NET Framework 4.7.2)
        if: github.event_name == 'pull_request' && steps.extract-data.outputs.peak_memory_mb != ''
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const currentData = JSON.parse(fs.readFileSync('csharp/Benchmarks/BenchmarkDotNet.Artifacts/results/benchmark-data.json', 'utf8'));

            let baselineData = [];
            try {
              baselineData = JSON.parse(fs.readFileSync('./cache/benchmark-data.json', 'utf8'));
            } catch (e) {
              console.log('No baseline data found');
            }

            const currentMetrics = {};
            currentData.forEach(item => { currentMetrics[item.name] = item.value; });
            const baselineMetrics = {};
            baselineData.forEach(item => { baselineMetrics[item.name] = item.value; });

            let tableRows = '';
            ['Min Execution Time (s)', 'Peak Memory (MB)', 'Allocated Memory (MB)', 'Gen2 Collections'].forEach(metricName => {
              const current = currentMetrics[metricName] || 0;
              const baseline = baselineMetrics[metricName] || 0;
              let change = 'N/A';
              let status = 'âž–';

              if (baseline > 0) {
                const changePercent = ((current - baseline) / baseline) * 100;
                change = (changePercent >= 0 ? '+' : '') + changePercent.toFixed(1) + '%';
                status = changePercent < -30 ? 'ðŸŸ¢' : changePercent > 30 ? 'âš ï¸' : 'âœ…';
              } else {
                change = 'New metric';
              }
              tableRows += `| ${metricName} | ${baseline.toFixed(3)} | ${current.toFixed(3)} | ${change} | ${status} |\n`;
            });

            const body = `## ðŸŽ¯ Benchmark Results (.NET Framework 4.7.2)

            | Metric | Baseline (main) | This PR | Change | Status |
            |--------|----------------|---------|--------|--------|
            ${tableRows}
            **Indicators:**
            - ðŸŸ¢ **Improvement** - Metric improved by >30%
            - âœ… **No significant change** - Within Â±30%
            - âš ï¸ **Regression** - Metric degraded by >30%
            - âž– **New metric** - No baseline data available

            ðŸ“Š [View detailed results](${context.payload.repository.html_url}/actions/runs/${context.runId})`;

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });

            const existingComment = comments.data.find(comment =>
              comment.user.login === 'github-actions[bot]' &&
              comment.body.includes('Benchmark Results (.NET Framework 4.7.2)')
            );

            if (existingComment) {
              await github.rest.issues.deleteComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: existingComment.id,
              });
            }

            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });
